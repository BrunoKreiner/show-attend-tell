{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGQZmiJkG4ov",
        "outputId": "d7d9c593-cf98-4c03-8a30-d347ffad20d0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
        "!unzip Flickr8k_Dataset.zip -d all_images\n",
        "!unzip Flickr8k_text.zip -d all_captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Dx6UCVUyHxTH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import json\n",
        "from time import time\n",
        "import pickle\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import torch\n",
        "\n",
        "image_path = \"../all_images/Flicker8k_Dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "IzhvmDljH2JA",
        "outputId": "65a6a0cc-7d82-4ee3-d9ae-913d1ce090c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tes awdouj'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(\"[^a-z]+\", \" \", text)\n",
        "  text = text.split()\n",
        "  text = [s for s in text if len(s)> 1]\n",
        "  text = \" \".join(text)\n",
        "  return text\n",
        "clean_text(\"Tes tç% awdoujç TçG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppGlcrTGKVBj",
        "outputId": "592fcc58-61a4-436c-e0c6-e7a269369073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6000\n",
            "['2513260012_03d33305cf', '2903617548_d3e38d7f88', '3338291921_fe7ae0c8f8', '488416045_1c6d903fe0', '2644326817_8f45080b87']\n",
            "1000\n",
            "['3385593926_d3e9c21170', '2677656448_6b7e7702af', '311146855_0b65fdb169', '1258913059_07c613f7ff', '241347760_d44c8d3a01']\n"
          ]
        }
      ],
      "source": [
        "train_file = open(train_file_path, \"r\").read()\n",
        "train = [row.split(\".\")[0] for row in train_file.split(\"\\n\")[:-1]]\n",
        "print(len(train))\n",
        "print(train[:5])\n",
        "\n",
        "\n",
        "test_file = open(test_file_path, 'r').read()\n",
        "test = [row.split(\".\")[0] for row in test_file.split(\"\\n\")[:-1]]\n",
        "print(len(test))\n",
        "print(test[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udz9q2Qgo-vc",
        "outputId": "3f54af16-dc0a-4818-d386-b317dadb83dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8093\n",
            "['<start> little baby plays croquet <end>', '<start> little girl plays croquet next to truck <end>', '<start> the child is playing croquette by the truck <end>', '<start> the kid is in front of car with put and ball <end>', '<start> the little boy is playing with croquet hammer and ball beside the car <end>']\n"
          ]
        }
      ],
      "source": [
        "caption_file = open(captions_path, \"r\").read()\n",
        "captions = {}\n",
        "all_captions = []\n",
        "\n",
        "word_to_idx = {}\n",
        "idx_to_word = {}\n",
        "\n",
        "for row in caption_file.split(\"\\n\"):\n",
        "    multiple_captions = []\n",
        "    key = row.split(\"#\")[0].split(\".\")[0]\n",
        "    caption = row.split(\"#\")[-1].split(\"\\t\")[-1]\n",
        "    caption = caption.replace('.', '')\n",
        "    caption = clean_text(caption)\n",
        "    caption = \"<start> \" + caption + \" <end>\"\n",
        "    all_captions.append(caption)\n",
        "    if  key not in captions:\n",
        "        captions[key] = []\n",
        "        captions[key].append(caption)\n",
        "    else:\n",
        "        captions[key].append(caption)\n",
        "\n",
        "print(len(captions))\n",
        "print(captions[\"2903617548_d3e38d7f88\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8426\n",
            "8425\n",
            "4795\n",
            "8425\n",
            "<start>\n"
          ]
        }
      ],
      "source": [
        "all_words = \"\"\n",
        "for word in captions.values():\n",
        "    all_words = all_words + \" \" + \" \".join(word)\n",
        "all_words = all_words[1:]\n",
        "all_words = all_words.split(\" \")[1:]\n",
        "print(len(set(all_words)))\n",
        "#print(set(all_words))\n",
        "all_words = list(set(all_words))\n",
        "print(len(all_words[1:]))\n",
        "i = 0\n",
        "for word in all_words[1:]:\n",
        "    #print(word)\n",
        "    word_to_idx[word] = i\n",
        "    idx_to_word[i] = word\n",
        "    i+=1\n",
        "\n",
        "print(word_to_idx[\"<start>\"])\n",
        "print(len(idx_to_word))\n",
        "print(idx_to_word[4795])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZsIoOXFktRGu"
      },
      "outputs": [],
      "source": [
        "#model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "#model = models.resnet152(pretrained=True)\n",
        "#newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "model = resnet50(weights=None)\n",
        "model = torch.nn.Sequential(*(list(model.children())[:-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC8QQiE7uMEu",
        "outputId": "f813f61b-dfcf-430c-9345-30df48c55fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2048])\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "\n",
        "import requests\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "preprocess = T.Compose([\n",
        "   T.Resize(256),\n",
        "   T.CenterCrop(224),\n",
        "   T.ToTensor()\n",
        "])\n",
        "\n",
        "\"\"\"T.Normalize(\n",
        "       mean=[0.485, 0.456, 0.406],\n",
        "       std=[0.229, 0.224, 0.225]\n",
        ")\"\"\"\n",
        "\n",
        "def preprocess_img(img):\n",
        "    img = Image.open(img, 'r')\n",
        "    img = preprocess(img)\n",
        "    return img\n",
        "\n",
        "def encode_image(img):\n",
        "    img = preprocess_img(img)\n",
        "    if len(img.shape) == 3:\n",
        "        img = img[None, :]\n",
        "    feature_vector = model(img)\n",
        "    feature_vector = feature_vector.reshape((-1,))\n",
        "    return feature_vector\n",
        "\n",
        "print(encode_image(image_path + \"1000268201_693b08cb0e.jpg\").shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "mUur0yJtxWV-",
        "outputId": "a3e348bd-1a0d-4a4d-9602-96e98384a102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding in Progress Time step 0\n",
            "Encoding in Progress Time step 100\n",
            "Encoding in Progress Time step 200\n",
            "Encoding in Progress Time step 300\n",
            "Encoding in Progress Time step 400\n",
            "Encoding in Progress Time step 500\n",
            "Encoding in Progress Time step 600\n",
            "Encoding in Progress Time step 700\n",
            "Encoding in Progress Time step 800\n",
            "Encoding in Progress Time step 900\n",
            "Encoding in Progress Time step 1000\n",
            "Encoding in Progress Time step 1100\n",
            "Encoding in Progress Time step 1200\n",
            "Encoding in Progress Time step 1300\n",
            "Encoding in Progress Time step 1400\n",
            "Encoding in Progress Time step 1500\n",
            "Encoding in Progress Time step 1600\n",
            "Encoding in Progress Time step 1700\n",
            "Encoding in Progress Time step 1800\n",
            "Encoding in Progress Time step 1900\n",
            "Encoding in Progress Time step 2000\n",
            "Encoding in Progress Time step 2100\n",
            "Encoding in Progress Time step 2200\n",
            "Encoding in Progress Time step 2300\n",
            "Encoding in Progress Time step 2400\n",
            "Encoding in Progress Time step 2500\n",
            "Encoding in Progress Time step 2600\n",
            "Encoding in Progress Time step 2700\n",
            "Encoding in Progress Time step 2800\n",
            "Encoding in Progress Time step 2900\n",
            "Encoding in Progress Time step 3000\n",
            "Encoding in Progress Time step 3100\n",
            "Encoding in Progress Time step 3200\n",
            "Encoding in Progress Time step 3300\n",
            "Encoding in Progress Time step 3400\n",
            "Encoding in Progress Time step 3500\n",
            "Encoding in Progress Time step 3600\n",
            "Encoding in Progress Time step 3700\n",
            "Encoding in Progress Time step 3800\n",
            "Encoding in Progress Time step 3900\n",
            "Encoding in Progress Time step 4000\n",
            "Encoding in Progress Time step 4100\n",
            "Encoding in Progress Time step 4200\n",
            "Encoding in Progress Time step 4300\n",
            "Encoding in Progress Time step 4400\n",
            "Encoding in Progress Time step 4500\n",
            "Encoding in Progress Time step 4600\n",
            "Encoding in Progress Time step 4700\n",
            "Encoding in Progress Time step 4800\n",
            "Encoding in Progress Time step 4900\n",
            "Encoding in Progress Time step 5000\n",
            "Encoding in Progress Time step 5100\n",
            "Encoding in Progress Time step 5200\n",
            "Encoding in Progress Time step 5300\n",
            "Encoding in Progress Time step 5400\n",
            "Encoding in Progress Time step 5500\n",
            "Encoding in Progress Time step 5600\n",
            "Encoding in Progress Time step 5700\n",
            "Encoding in Progress Time step 5800\n",
            "Encoding in Progress Time step 5900\n",
            "Total Time Taken:  0.0062220096588134766\n"
          ]
        }
      ],
      "source": [
        "start_t = time()\n",
        "encoding_train = {}\n",
        "\n",
        "for ix, img_id in enumerate(train):\n",
        "    img_path = image_path + img_id + \".jpg\"\n",
        "    #encoding_train[img_id] = encode_image(img_path)\n",
        "\n",
        "    if ix%100==0:\n",
        "        print(\"Encoding in Progress Time step %d\"%ix)\n",
        "end_t = time()\n",
        "print(\"Total Time Taken: \", end_t-start_t)\n",
        "\n",
        "with open(\"saved_encoded_train_features.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoding_train, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "counter = collections.Counter(all_words)\n",
        "dic = dict(counter)\n",
        "\n",
        "threshold_value = 10\n",
        "sorted_dic = sorted(dic.items(), reverse=True, key=lambda x: x[1])\n",
        "sorted_dic = [x for x in sorted_dic if x[1] > threshold_value]\n",
        "\n",
        "all_words = [x[0] for x in sorted_dic]\n",
        "print(len(all_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35\n"
          ]
        }
      ],
      "source": [
        "max_len = 0\n",
        "for key in captions.keys():\n",
        "    for cap in captions[key]:\n",
        "        max_len = max(max_len, len(cap.split()))\n",
        "\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8426"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400000\n",
            "(8426, 50) 8425\n",
            "(8426, 50)\n"
          ]
        }
      ],
      "source": [
        "f = open(\"../data/glove.6B.50d.txt\", encoding='utf8')\n",
        "embedding_index = {}\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_index[word] = vector\n",
        "\n",
        "f.close()\n",
        "\n",
        "print(len(embedding_index))\n",
        "\n",
        "def get_embedding_matrix():\n",
        "    emb_dim = 50\n",
        "    embedding_matrix = np.zeros((len(all_words[1:])+1, emb_dim))\n",
        "    print(embedding_matrix.shape, len(word_to_idx))\n",
        "    for word, idx in word_to_idx.items():\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[idx] = embedding_vector\n",
        "    \n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix = get_embedding_matrix()\n",
        "print(embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.decoder = nn.Linear(2040, 1020)\n",
        "        self.lstm = nn.LSTM(1020, 25)\n",
        "        self.label = nn.Linear(100, 100)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \n",
        "        return self.label(final_hidden_state[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 2048, 1, 1])"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(torch.zeros(1,3,32,100)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(2040, 100)\n",
              "  (label): Linear(in_features=100, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm = LSTM()\n",
        "lstm"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "attend-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "62995a370ae3314effbb36182e9d1995abf6a762b19f16d2ba0d8511ef94114d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
